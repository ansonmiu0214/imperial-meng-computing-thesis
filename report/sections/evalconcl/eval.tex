\chapter{Evaluation}
\label{chap:eval}
%benchmark -- compile time / benchmarking 

\section{Binary Sessions: \fancyname{Calculator}}
\begin{itemize}
\item sample client implementation + snippet of generated code (full in appendix)
\item show that not all the UI is being controlled by the runtime (i.e. calculator app has a header/fake navbar)
\item show the calculator logic achievable using React Context
\item sample server implementation + snippet of generated code (full in appendix)
\end{itemize}

\section{Multiparty Sessions: \fancyname{Noughts and Crosses}}
\begin{itemize}
\item sample client implementation -- show the flexibility of factory API for sending to be used in the UI part (since move selection can be be made )
\end{itemize}

\section{Routed Multiparty Sessions: \fancyname{Two Buyers}}
\begin{itemize}
\item show that the routing aspect is transparent to both sides
\end{itemize}

\section{Performance Benchmarks}

Whilst web applications that implement our generated APIs enjoy
communication safety guarantees, the presence of the session runtime acts
as an additional layer of abstraction between the application logic and the
WebSocket transport, which is likely to present a performance trade-off.

\begin{figure}[!ht]
\begin{lstlisting}[language=Scribble]
global protocol PingPong(role Client, role Svr) {
	PING(number) from Client to Svr;
	choice at Svr {
		PONG(number) from Svr to Client;
		do PingPong(Client, Svr);
	} or {
		BYE(number) from Svr to Client;	
	}
}
\end{lstlisting}
\captionof{lstlisting}{Ping Pong Protocol}
\label{lst:pingpong}
\end{figure}

To measure the overhead of our implementation, we compare the
execution time of an interactive web application implementing the
Ping Pong protocol (\cref{lst:pingpong}) using our generated APIs,
against implementations of the protocol \textit{without} session types.

We standardise the application logic across experiments to be 
parameterised by the number of round trip messages, $n > 0$.
Upon establishing a connection, the experiment proceeds as follow:

\begin{enumerate}

\item \trole{Client} sends \tmsg{PING($m$:number)} to \trole{Svr}, 
with $m = 0$ initially.

\item \trole{Svr} receives \tmsg{PING($m$:number)}, and
conditionally responds based on $n$:

\begin{enumerate}
\item If $m + 1 < n$, then \trole{Svr} replies \tmsg{PONG($m + 1$)}.
\trole{Client} responds to \tmsg{PONG} by returning to
step 1 with $m$ set as the payload from \tmsg{PONG}.

\item Otherwise, $m + 1 = n$, then \trole{Svr} responds with 
\tmsg{BYE($m + 1$)}, as $n$ round trips have taken place. 
\trole{Client} responds to \tmsg{BYE} by 
closing the connection, thus ending the experiment.
\end{enumerate}

\end{enumerate}

We note that the Ping Pong protocol implements a \textit{binary} session. 
It would be interesting to observe the overhead in a \textit{multiparty}
context, but due to limited time constraints, we were unable to 
extend our benchmarking suite to support multiple browser targets.
Benchmarking multiparty protocols would also require writing multiple
distinct React applications using the generated APIs -- as this is currently
a manual process, doing this for multiple roles requires more time than
available.

\subsection{Setup}

% mention that it is hard to simulate multi-party sessions 
% and see the overhead with increasing roles (eg ping pong with 50 roles)
% , because of the need to
% mock developer implementations for those roles

In order to measure the overhead as accurately as possible,
we outline the logic that all implementations must follow:

\subparagraph{Ping Pong \trole{Client} on React:}
\begin{itemize}

\item All \trole{Client}s implement the same user interface, rendering
a \texttt{<button>} which triggers the send, and
a \texttt{<div>} captioned with the number of \tmsg{PONG}s received.

\item \trole{Client}s will use the React Context API to manage 
application state, i.e. the number of \tmsg{PONG}s received. 
Session logic will be wrapped in a \texttt{ContextProvider}.

\item We use the production build generated by 
\texttt{create-react-app} \cite{cra} for all experiments, which performs the
transpilation into JavaScript.

\item We serve the production build on \url{localhost:3000} using the
\texttt{serve} package \cite{npmserve} available on \texttt{npm}.

\end{itemize}

\subparagraph{Ping Pong \trole{Svr} on Node}
\begin{itemize}

\item timing using console.time

\item start timing when connected

\item stop timing when close

\item using transpiled version

\end{itemize}

We run the experiments under a network of latency 0.165ms
(64 bytes ping), and repeat each experiment 20 times.
Execution time measurements  are taken using a machine 
equipped with Intel i7-4850HQ CPU (2.3 GHz, 4 cores, 8 threads), 
16 GB RAM, macOS operating system version 10.15.4, 
Node.js runtime version 12.12.0, and
TypeScript compiler version 3.7.4.
We standardise all packages used in the front- and back-end
implementations across experiments. Details can be found in their
corresponding \texttt{package.json} files (\cref{appendix:eval}).

We run our experiments using three implementations of the Ping Pong protocol:

\begin{itemize}

\item The \texttt{bare} implementation directly interfaces with 
WebSocket primitives for sending and receiving. 

\item The \texttt{bare_safe} implementation \dots

\item The \texttt{mpst} implementation \dots

\end{itemize}


\subsection{Execution Pattern}

\subsection{Analysing Overhead}
