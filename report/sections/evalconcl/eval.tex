\chapter{Evaluation}
\label{chap:eval}
%benchmark -- compile time / benchmarking 

\section{Binary Sessions: \fancyname{Calculator}}
\begin{itemize}
\item sample client implementation + snippet of generated code (full in appendix)
\item show that not all the UI is being controlled by the runtime (i.e. calculator app has a header/fake navbar)
\item show the calculator logic achievable using React Context
\item sample server implementation + snippet of generated code (full in appendix)
\end{itemize}

\section{Multiparty Sessions: \fancyname{Noughts and Crosses}}
\begin{itemize}
\item sample client implementation -- show the flexibility of factory API for sending to be used in the UI part (since move selection can be be made )
\end{itemize}

\section{Routed Multiparty Sessions: \fancyname{Two Buyers}}
\begin{itemize}
\item show that the routing aspect is transparent to both sides
\end{itemize}

\section{Performance Benchmarks}

Whilst web applications that implement our generated APIs enjoy
communication safety guarantees, the presence of the session runtime acts
as an additional layer of abstraction between the application logic and the
WebSocket transport, which is likely to present a performance trade-off.

To measure the overhead of our implementation, we compare the
execution time of an interactive web application implementing the
Ping Pong protocol (\cref{fig:pingpong}) using our generated APIs
against an implementation of the protocol without session types.

We standardise the application logic across experiments to be 
parameterised by the number of round trip messages, $n$.
Upon establishing a connection, the experiment proceeds as follow:

\begin{enumerate}

\item \trole{Client} sends a \tmsg{PING($m$:number)} message, 
with $m = 0$ initially.

\item \trole{Server} receives the \tmsg{PING($m$:number)} message, and
conditionally responds based on the experiment parameter $n$:

\begin{enumerate}
\item If $m + 1 < n$, then \trole{Server} responds with \tmsg{PONG($m + 1$)}.
\trole{Client} responds to the \tmsg{PONG} message by returning to
step 1 with $m$ set as the payload of the received \tmsg{PONG} message.

\item Otherwise, $m + 1 = n$, then \trole{Server} responds with 
\tmsg{BYE($m + 1$)}, as $n$ round trips have taken place. 
\trole{Client} responds to the
\tmsg{BYE} message by closing the connection, thus ending the experiment.
\end{enumerate}

\end{enumerate}

%\begin{itemize}
%\item compile time: \begin{itemize}
%\item use the examples from above to compare compilation time
%\end{itemize}
%\item execution time: based on parameterised ping pong with n messages
%\begin{itemize}
%\item n = 10, 100, 1000
%\item benchmark using node timer tools in the backend as it knows when the protocol ends
%\end{itemize}
%\end{itemize}

\subsection{Setup}

% mention that it is hard to simulate multi-party sessions 
% and see the overhead with increasing roles (eg ping pong with 50 roles)
% , because of the need to
% mock developer implementations for those roles

We run the experiments under a network of latency 0.165ms
(64 bytes ping), and repeat each experiment 20 times.
Compilation time and execution time measurements 
are taken using a machine equipped with Intel i7-4850HQ CPU
(2.3 GHz, 4 cores, 8 threads), 16 GB RAM, macOS operating system 
version 10.15.4, Node.js runtime version 12.12.0, and
TypeScript compiler version 3.7.4.

The other packages used in all implementations are outlined in their
corresponding \texttt{package.json} files.

\paragraph{\fancyname{Bare} variant}
\dots

\paragraph{\fancyname{BareSafe} variant}
\dots

\paragraph{\fancyname{MPST} variant}
\dots

\subsection{Execution Pattern}

\subsection{Analysing Overhead}
